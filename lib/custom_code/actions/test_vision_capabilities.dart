// Automatic FlutterFlow imports
import '/flutter_flow/flutter_flow_theme.dart';
import '/flutter_flow/flutter_flow_util.dart';
import 'index.dart'; // Imports other custom actions
import 'package:flutter/material.dart';
// Begin custom action code
// DO NOT REMOVE OR MODIFY THE CODE ABOVE!

import '../GemmaManager.dart';

Future<String> testVisionCapabilities() async {
  try {
    print('=== VISION CAPABILITY TEST START ===');
    
    final gemmaManager = GemmaManager();
    
    // Check if model is initialized
    if (!gemmaManager.isInitialized) {
      return 'ERROR: No model is currently initialized. Please set up a model first.';
    }
    
    // Report current model details
    final modelType = gemmaManager.currentModelType ?? 'Unknown';
    final backend = gemmaManager.currentBackend ?? 'Unknown';
    final supportsVision = gemmaManager.supportsVision;
    
    print('Current model: $modelType');
    print('Backend: $backend');
    print('Claims vision support: $supportsVision');
    
    // Check if session exists
    if (!gemmaManager.hasSession) {
      print('No session found, attempting to create one...');
      final sessionCreated = await gemmaManager.createSession();
      if (!sessionCreated) {
        return 'ERROR: Could not create session for vision testing.';
      }
    }
    
    print('Starting comprehensive vision capability tests...');
    final testResults = await gemmaManager.testVisionCapabilities();
    
    // Format results for user
    final buffer = StringBuffer();
    buffer.writeln('=== VISION CAPABILITY TEST RESULTS ===\n');
    
    buffer.writeln('Model: ${gemmaManager.currentModelType}');
    buffer.writeln('Backend: ${gemmaManager.currentBackend}\n');
    
    // Overall status
    buffer.writeln('üìä OVERALL STATUS:');
    buffer.writeln('‚Ä¢ Model Ready: ${testResults['isReady'] ? '‚úÖ' : '‚ùå'}');
    buffer.writeln('‚Ä¢ Claims Vision Support: ${testResults['supportsVision'] ? '‚úÖ' : '‚ùå'}');
    buffer.writeln('‚Ä¢ Can Process Images: ${testResults['canProcessImages'] ? '‚úÖ' : '‚ùå'}');
    buffer.writeln('‚Ä¢ Responds to Images: ${testResults['respondsToImages'] ? '‚úÖ' : '‚ùå'}');
    buffer.writeln('‚Ä¢ Gives Reasonable Responses: ${testResults['givesReasonableResponses'] ? '‚úÖ' : '‚ùå'}\n');
    
    // Errors
    if (testResults['errors'] != null && (testResults['errors'] as List).isNotEmpty) {
      buffer.writeln('‚ö†Ô∏è ERRORS:');
      for (final error in testResults['errors'] as List) {
        buffer.writeln('‚Ä¢ $error');
      }
      buffer.writeln();
    }
    
    // Individual test results
    final testData = testResults['testResults'] as Map<String, dynamic>?;
    if (testData != null) {
      buffer.writeln('üß™ INDIVIDUAL TESTS:');
      
      for (final entry in testData.entries) {
        final testName = entry.key;
        final testResult = entry.value as Map<String, dynamic>;
        
        buffer.writeln('\n${testName.toUpperCase()}:');
        buffer.writeln('  Responded: ${testResult['responded'] ? '‚úÖ' : '‚ùå'}');
        
        if (testResult['response'] != null) {
          final response = testResult['response'] as String;
          buffer.writeln('  Response: "${response.length > 100 ? '${response.substring(0, 100)}...' : response}"');
        }
        
        if (testResult['error'] != null) {
          buffer.writeln('  Error: ${testResult['error']}');
        }
      }
    }
    
    // Recommendations
    buffer.writeln('\nüí° RECOMMENDATIONS:');
    
    if (!testResults['isReady']) {
      buffer.writeln('‚Ä¢ Initialize a model and create a session before testing vision');
    } else if (!testResults['supportsVision']) {
      buffer.writeln('‚Ä¢ Use a multimodal model that supports vision (e.g., Gemma 3)');
    } else if (!testResults['canProcessImages']) {
      buffer.writeln('‚Ä¢ Vision processing appears to be non-functional');
      buffer.writeln('‚Ä¢ Check if the model file is properly installed');
      buffer.writeln('‚Ä¢ Try restarting the app and reinitializing the model');
    } else if (!testResults['respondsToImages']) {
      buffer.writeln('‚Ä¢ Model can process images but responses are inconsistent');
      buffer.writeln('‚Ä¢ Try simpler images with high contrast');
      buffer.writeln('‚Ä¢ Consider using text-based images or diagrams');
    } else if (!testResults['givesReasonableResponses']) {
      buffer.writeln('‚Ä¢ Model responds but gives hallucinated/problematic answers');
      buffer.writeln('‚Ä¢ This appears to be a limitation of the on-device model');
      buffer.writeln('‚Ä¢ Try images with clear text, simple shapes, or high contrast');
      buffer.writeln('‚Ä¢ Consider cloud-based vision APIs for complex natural images');
    } else {
      buffer.writeln('‚Ä¢ Vision capabilities appear to be working properly!');
      buffer.writeln('‚Ä¢ Model should be able to handle image analysis tasks');
    }
    
    buffer.writeln('\n=== END VISION TEST ===');
    
    final result = buffer.toString();
    print(result);
    return result;
    
  } catch (e) {
    final error = 'Vision capability test failed: $e';
    print(error);
    return error;
  }
}